{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR8Aiq7AtvAZ",
        "outputId": "67c035d4-67be-4493-b2f7-66b057696a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (1.1.1)\n",
            "Requirement already satisfied: matplotlib in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from catboost) (3.6.1)\n",
            "Requirement already satisfied: scipy in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from catboost) (1.9.3)\n",
            "Requirement already satisfied: plotly in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from catboost) (5.11.0)\n",
            "Requirement already satisfied: graphviz in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from catboost) (1.23.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from catboost) (1.5.2)\n",
            "Requirement already satisfied: six in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from matplotlib->catboost) (1.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from matplotlib->catboost) (9.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from matplotlib->catboost) (4.38.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from plotly->catboost) (8.1.0)\n",
            "Requirement already satisfied: keras in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (2.10.0)\n",
            "Requirement already satisfied: scikit-learn in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (1.1.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from scikit-learn) (1.23.2)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: xgboost in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (1.7.1)\n",
            "Requirement already satisfied: numpy in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from xgboost) (1.23.2)\n",
            "Requirement already satisfied: scipy in /Users/fishies/miniforge3/envs/tsf/lib/python3.10/site-packages (from xgboost) (1.9.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install keras\n",
        "!pip install -U scikit-learn\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7es6hYrBgOk",
        "outputId": "28157a66-b05b-4aba-eef2-2c27fb9a625d"
      },
      "outputs": [],
      "source": [
        "!rm -rf defi-ai && git clone --quiet https://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@github.com/vnghia/defi-ai\n",
        "!pip install defi-ai/ -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TgaairkXBmfU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HOST_URL\"] = \"http://51.91.251.0:3000\"\n",
        "os.environ[\"USER_ID\"] = \"f89fec0b-183b-4921-bf15-197101c14192\"\n",
        "os.environ[\"SQL_USERNAME\"] = \"postgres\"\n",
        "os.environ[\"SQL_PASSWORD\"] = \"^de<@TETh~}*;:/*\"\n",
        "os.environ[\"SQL_HOST\"] = \"34.155.175.170\"\n",
        "os.environ[\"SQL_PORT\"] = \"5432\"\n",
        "os.environ[\"SQL_SCRAPE_DATABASE\"] = \"scrape\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Oph0tFtIBsuD"
      },
      "outputs": [],
      "source": [
        "from defi_ai import Hotel, Request, Sample, init_session\n",
        "import pandas as pd\n",
        "Session = init_session()\n",
        "session = Session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T7O4vLcNtQh6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Neural networks\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Add, Input, Dense, Dropout, BatchNormalization, Embedding, Flatten, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.regularizers import l1\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NCstz3aCBziL"
      },
      "outputs": [],
      "source": [
        "df = Request.load_dataset(session, False)\n",
        "df = df[['language', 'city', 'date', 'mobile', 'group', 'brand', 'parking',\n",
        "       'pool', 'children_policy', 'stock', 'request_count','price']]\n",
        "sample = Sample.load_dataset(session)\n",
        "sample=sample[['language', 'city', 'date', 'mobile', 'group', 'brand', 'parking',\n",
        "       'pool', 'children_policy', 'stock', 'request_count']]\n",
        "df = df.astype(int)\n",
        "sample = sample.astype(int)\n",
        "X_train = df.drop(['price'],axis =1)\n",
        "y_train = df['price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qimy45csuiAf"
      },
      "outputs": [],
      "source": [
        "def create_neural_network(input_shape, depth=5, batch_mod=2, num_neurons=20, drop_rate=0.1, learn_rate=.01,\n",
        "                      r1_weight=0.02,\n",
        "                      r2_weight=0.02):\n",
        "    act_reg = l1(r2_weight)\n",
        "    kern_reg = l1(r1_weight)\n",
        "    \n",
        "    inputs = Input(shape=(input_shape,))\n",
        "    batch1 = BatchNormalization()(inputs)\n",
        "    hidden1 = Dense(num_neurons, activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(batch1)\n",
        "    dropout1 = Dropout(drop_rate)(hidden1)\n",
        "    hidden2 = Dense(int(num_neurons/2), activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(dropout1)\n",
        "    \n",
        "    skip_list = [batch1]\n",
        "    last_layer_in_loop = hidden2\n",
        "    \n",
        "    for i in range(depth):\n",
        "        added_layer = concatenate(skip_list + [last_layer_in_loop])\n",
        "        skip_list.append(added_layer)\n",
        "        b1 = None\n",
        "        #Apply batch only on every i % N layers\n",
        "        if i % batch_mod == 2:\n",
        "            b1 = BatchNormalization()(added_layer)\n",
        "        else:\n",
        "            b1 = added_layer\n",
        "        \n",
        "        h1 = Dense(num_neurons, activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(b1)\n",
        "        d1 = Dropout(drop_rate)(h1)\n",
        "        h2 = Dense(int(num_neurons/2), activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(d1)\n",
        "        d2 = Dropout(drop_rate)(h2)\n",
        "        h3 =  Dense(int(num_neurons/2), activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(d2)\n",
        "        d3 = Dropout(drop_rate)(h3)\n",
        "        h4 =  Dense(int(num_neurons/2), activation='relu', kernel_regularizer=kern_reg, activity_regularizer=act_reg)(d3)\n",
        "        last_layer_in_loop = h4\n",
        "        c1 = concatenate(skip_list + [last_layer_in_loop])\n",
        "        output = Dense(1, activation='sigmoid')(c1)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    optimizer = Adam()\n",
        "    optimizer.learning_rate = learn_rate\n",
        "    \n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='mse',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xNei-Yf2vejh"
      },
      "outputs": [],
      "source": [
        "def get_stacking(input_shape=None):\n",
        "    level0 = list()\n",
        "    level0.append(('cat', CatBoostRegressor(verbose=False,learning_rate=0.01,random_state=24)))\n",
        "    level0.append(('cat2', CatBoostRegressor(verbose=False, learning_rate=.015,random_state=24)))\n",
        "    level0.append(('cat3', CatBoostRegressor(verbose=False, learning_rate=.0125,random_state=24)))\n",
        "    level0.append(('xgb', XGBRegressor()))\n",
        "    level0.append(('rf', RandomForestRegressor(verbose=False)))\n",
        "    # level0.append(('SGD', SGDRegressor()))\n",
        "    # level0.append(('Ridge', Ridge()))\n",
        "    # level0.append(('Lasso', Lasso()))\n",
        "    # level0.append(('KNR', KNeighborsRegressor()))\n",
        "    # level0.append(('ADA', AdaBoostRegressor()))\n",
        "    # level0.append(('DTR', DecisionTreeRegressor()))\n",
        "    # level0.append(('GBR', GradientBoostingRegressor()))\n",
        "\n",
        "    for i in range(10):\n",
        "        keras_reg = KerasRegressor(\n",
        "                create_neural_network, # Pass in function\n",
        "                input_shape=input_shape, # Pass in the dimensions to above function\n",
        "                epochs=10,\n",
        "                batch_size=32,\n",
        "                verbose=False)\n",
        "        keras_reg._estimator_type = \"regressor\"\n",
        "        # Append to our list\n",
        "        level0.append(('nn_{num}'.format(num=i), keras_reg))\n",
        "\n",
        "    level1 = CatBoostRegressor(verbose=False, learning_rate=.0125,random_state=24)\n",
        "    # Create the stacking ensemble\n",
        "    model = StackingRegressor(estimators=level0, final_estimator=level1, cv=2, verbose=1)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSZ-vpkvwfo2",
        "outputId": "cbe86f0c-8b60-4f94-8af1-c8849a4e3b19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/kt/6408rcfs0s799svmhtqblzyh0000gn/T/ipykernel_14423/68588552.py:24: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  keras_reg = KerasRegressor(\n",
            "2022-11-25 23:02:53.065976: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   41.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   40.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   39.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.7min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.6min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.5min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  9.0min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  9.1min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  9.0min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.8min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.5min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.5min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.4min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.2min finished\n"
          ]
        }
      ],
      "source": [
        "#Get our input dimensions for neural network\n",
        "input_dimensions = len(X_train.columns)\n",
        "# Create stacking model\n",
        "model = get_stacking(input_dimensions)\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "temp = pd.DataFrame()\n",
        "\n",
        "temp['price'] = model.predict(sample)\n",
        "\n",
        "# for m in model.named_estimators_:\n",
        "#         temp[m] = model.named_estimators_[m].predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "tempF = pd.DataFrame()\n",
        "for m in model.named_estimators_:\n",
        "        tempF[m] = model.named_estimators_[m].predict(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp.to_csv('./sub.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://b5148c74-8b95-4049-9f22-58e3e774d9ca/assets\n",
            "INFO:tensorflow:Assets written to: ram://d5fcefd1-fc3e-48f2-87da-94600e842696/assets\n",
            "INFO:tensorflow:Assets written to: ram://6478e610-11a4-40cd-966a-b1ac1461fb2d/assets\n",
            "INFO:tensorflow:Assets written to: ram://4badba85-7209-487e-a1a5-052997aa540a/assets\n",
            "INFO:tensorflow:Assets written to: ram://10a37639-e79d-462b-aa17-c32fb7c1a1f5/assets\n",
            "INFO:tensorflow:Assets written to: ram://848b47f8-a823-4c31-8059-9d36675dd410/assets\n",
            "INFO:tensorflow:Assets written to: ram://b73a8fca-3513-4377-8aa0-cba3fcfb8c0b/assets\n",
            "INFO:tensorflow:Assets written to: ram://06a1771d-c53b-48b6-9cb4-c743e8e652e4/assets\n",
            "INFO:tensorflow:Assets written to: ram://a0b46620-ae3e-4899-896f-e6c5683df3b3/assets\n",
            "INFO:tensorflow:Assets written to: ram://c1b477c3-44d0-443f-b253-0bdfd685700a/assets\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "pkl_filename = \"mmm.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 ('tsf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "696c481bfb1f8339b0cd064dc8ad656171a3cca29a9a26d5884a0e847d2753a4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
