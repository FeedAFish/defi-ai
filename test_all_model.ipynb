{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0k9f5H4XClJr",
        "outputId": "3495eb36-6bd5-495a-d8fb-64ec4061cfc6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('bmh')                    \n",
        "sns.set_style({'axes.grid':False}) \n",
        "\n",
        "'''Plotly visualization .'''\n",
        "import plotly.offline as py\n",
        "from plotly.offline import iplot, init_notebook_mode\n",
        "import plotly.graph_objs as go\n",
        "init_notebook_mode(connected = True)\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "302oIAuBAldS"
      },
      "outputs": [],
      "source": [
        "'''Set a seed for reproducibility'''\n",
        "seed = 43\n",
        "import pandas as pd\n",
        "'''Initialize all the regression models object we are interested in.'''\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "# from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "# from lightgbm import LGBMRegressor\n",
        "\n",
        "\n",
        "'''We are interested in the following 14 regression models.\n",
        "All initialized with default parameters except random_state and n_jobs.'''\n",
        "linear = LinearRegression(n_jobs = -1)\n",
        "lasso = Lasso(random_state = seed)\n",
        "ridge = Ridge(random_state = seed)\n",
        "# kr = KernelRidge()\n",
        "elnt = ElasticNet(random_state = seed)\n",
        "dt = DecisionTreeRegressor(random_state = seed)\n",
        "# svm = SVR()\n",
        "knn = KNeighborsRegressor(n_jobs = -1)\n",
        "rf =  RandomForestRegressor(n_jobs = -1, random_state = seed)\n",
        "et = ExtraTreesRegressor(n_jobs = -1, random_state = seed)\n",
        "ab = AdaBoostRegressor(random_state = seed)\n",
        "gb = GradientBoostingRegressor(random_state = seed)\n",
        "xgb = XGBRegressor(random_state = seed, n_jobs = -1)\n",
        "# lgb = LGBMRegressor(random_state = seed, n_jobs = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViJY18KIApEf",
        "outputId": "020d2dfc-501c-4e35-c91c-f9a7b481f146"
      },
      "outputs": [],
      "source": [
        "!rm -rf defi-ai && git clone --quiet https://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@github.com/vnghia/defi-ai\n",
        "!pip install defi-ai/ -q\n",
        "import os\n",
        "\n",
        "os.environ[\"HOST_URL\"] = \"http://51.91.251.0:3000\"\n",
        "os.environ[\"USER_ID\"] = \"f89fec0b-183b-4921-bf15-197101c14192\"\n",
        "os.environ[\"SQL_USERNAME\"] = \"postgres\"\n",
        "os.environ[\"SQL_PASSWORD\"] = \"^de<@TETh~}*;:/*\"\n",
        "os.environ[\"SQL_HOST\"] = \"34.155.175.170\"\n",
        "os.environ[\"SQL_PORT\"] = \"5432\"\n",
        "os.environ[\"SQL_SCRAPE_DATABASE\"] = \"scrape\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l34rrO49A59O"
      },
      "outputs": [],
      "source": [
        "from defi_ai import Hotel, Request, Sample, init_session\n",
        "import pandas as pd\n",
        "Session = init_session()\n",
        "session = Session()\n",
        "\n",
        "df = Request.load_dataset(session, False)\n",
        "df = df[['language', 'city', 'date', 'mobile', 'group', 'brand', 'parking',\n",
        "       'pool', 'children_policy', 'stock', 'request_count','price']]\n",
        "sample = Sample.load_dataset(session)\n",
        "sample=sample[['language', 'city', 'date', 'mobile', 'group', 'brand', 'parking',\n",
        "       'pool', 'children_policy', 'stock', 'request_count']]\n",
        "df = df.astype(int)\n",
        "sample = sample.astype(int)\n",
        "X_train = df.drop(['price'],axis =1)\n",
        "df_train_final = X_train\n",
        "y_train = df['price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# path = os.path.abspath(os.getcwd())\n",
        "# df = pd.read_csv(path + \"/data/ready_data.csv\")\n",
        "# df=df.drop(['Unnamed: 0'],axis=1)\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sample = pd.read_csv(path + \"/data/ready_sample.csv\")\n",
        "# sample=sample.drop(['Unnamed: 0'],axis =1).sort_values(by=\"id\")[df.drop(['price'],axis =1).columns]\n",
        "# sample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df = df.astype(int)\n",
        "# sample = sample.astype(int)\n",
        "# X_train = df.drop(['price'],axis =1)\n",
        "# df_train_final = X_train\n",
        "# y_train = df['price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEDbSUmDBDZq"
      },
      "outputs": [],
      "source": [
        "'''Training accuracy of our regression models. By default score method returns coefficient of determination (r_squared).'''\n",
        "def train_r2(model):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model.score(X_train, y_train)\n",
        "\n",
        "'''Calculate and plot the training accuracy.'''\n",
        "models = [linear, lasso, ridge, elnt, dt, knn, rf, et, ab, gb, xgb]\n",
        "training_score = []\n",
        "for i,model in enumerate(models):\n",
        "    training_score.append(train_r2(model))\n",
        "    print(i)\n",
        "    \n",
        "'''Plot dataframe of training accuracy.'''\n",
        "train_score = pd.DataFrame(data = training_score, columns = ['Training_R2'])\n",
        "train_score.index = ['LR', 'LSO', 'RIDGE', 'ELNT', 'DT', 'KNN', 'RF', 'ET', 'AB', 'GB', 'XGB']\n",
        "train_score = (train_score*100).round(4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O48PMDlEBs7_"
      },
      "outputs": [],
      "source": [
        "'''Evaluate models on the holdout set(say on 30%).'''\n",
        "def train_test_split_score(model):\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(df_train_final, y_train, test_size = 0.3, random_state = seed)\n",
        "    model.fit(X_train, Y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "    mse = mean_squared_error(prediction, Y_test)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return rmse\n",
        "\n",
        "'''Calculate train_test_split score of differnt models and plot them.'''\n",
        "models = [lasso, ridge, elnt, dt, knn, rf, et, ab, gb, xgb]\n",
        "train_test_split_rmse = []\n",
        "for i,model in enumerate(models):\n",
        "    train_test_split_rmse.append(train_test_split_score(model))\n",
        "    print(i)\n",
        "\n",
        "'''Plot data frame of train test rmse'''\n",
        "train_test_score = pd.DataFrame(data = train_test_split_rmse, columns = ['Train_Test_RMSE'])\n",
        "train_test_score.index = ['LSO', 'RIDGE', 'ELNT', 'DT', 'KNN', 'RF', 'ET', 'AB', 'GB', 'XGB']\n",
        "train_test_score = train_test_score.round(5)\n",
        "x = train_test_score.index\n",
        "y = train_test_score['Train_Test_RMSE']\n",
        "title = \"Models' Test Score (RMSE) on Holdout(30%) Set\"\n",
        "# sns.scatterplot(x, y, title, 'Models','RMSE', 30, 'RdBu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_test_score = pd.DataFrame(data = train_test_split_rmse, columns = ['Train_Test_RMSE'])\n",
        "train_test_score.index = ['LSO', 'RIDGE', 'ELNT', 'DT', 'KNN', 'RF', 'ET', 'AB', 'GB', 'XGB']\n",
        "train_test_score = train_test_score.round(5)\n",
        "x = train_test_score.index\n",
        "y = train_test_score['Train_Test_RMSE']\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeNe8ez6Bw9B"
      },
      "outputs": [],
      "source": [
        "'''Function to compute cross validation scores.'''\n",
        "def cross_validate(model):\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    neg_x_val_score = cross_val_score(model, df_train_final, y_train, cv = 10, n_jobs = -1, scoring = 'neg_mean_squared_error')\n",
        "    x_val_score = np.round(np.sqrt(-1*neg_x_val_score), 5)\n",
        "    return x_val_score.mean()\n",
        "\n",
        "'''Calculate cross validation score of differnt models and plot them.'''\n",
        "models = [lasso, ridge, elnt, dt, knn, rf, et, ab, gb, xgb]\n",
        "cross_val_scores = []\n",
        "for model in models:\n",
        "    cross_val_scores.append(cross_validate(model))\n",
        "\n",
        "'''Plot data frame of cross validation scores.'''\n",
        "x_val_score = pd.DataFrame(data = cross_val_scores, columns = ['Cross Validation Scores (RMSE)'])\n",
        "x_val_score.index = ['LSO', 'RIDGE', 'ELNT', 'DT', 'KNN', 'RF', 'ET', 'AB', 'GB', 'XGB']\n",
        "x_val_score = x_val_score.round(5)\n",
        "x = x_val_score.index\n",
        "y = x_val_score['Cross Validation Scores (RMSE)']\n",
        "# sns.scatter_plot(x, y, title, 'Models','RMSE', 30, 'Viridis')\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVFiJxPAB3iW"
      },
      "outputs": [],
      "source": [
        "def grid_search_cv(model, params):\n",
        "    global best_params, best_score\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator = model, param_grid = params, cv = 10, verbose = 1,\n",
        "                            scoring = 'neg_mean_squared_error', n_jobs = -1)\n",
        "    grid_search.fit(df_train_final, y_train)\n",
        "    best_params = grid_search.best_params_ \n",
        "    best_score = np.sqrt(-1*(np.round(grid_search.best_score_, 5)))\n",
        "    return best_params, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SztKMFCB6Pz"
      },
      "outputs": [],
      "source": [
        "''''Define hyperparameters of lasso.'''\n",
        "alpha = [0.0001, 0.0002, 0.00025, 0.0003, 0.00031, 0.00032, 0.00033, 0.00034, 0.00035, 0.00036, 0.00037, 0.00038, \n",
        "         0.0004, 0.00045, 0.0005, 0.00055, 0.0006, 0.0008,  0.001, 0.002, 0.005, 0.007, 0.008, 0.01]\n",
        "\n",
        "lasso_params = {'alpha': alpha,\n",
        "               'random_state':[seed]}\n",
        "\n",
        "grid_search_cv(lasso, lasso_params)\n",
        "lasso_best_params, lasso_best_score = best_params, best_score\n",
        "print('Lasso best params:{} & best_score:{:0.5f}' .format(lasso_best_params, lasso_best_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nBfT0l7B8t4"
      },
      "outputs": [],
      "source": [
        "''''Define hyperparameters of ridge.'''\n",
        "ridge_params = {'alpha':[ 9, 9.2, 9.4, 9.5, 9.52, 9.54, 9.56, 9.58, 9.6, 9.62, 9.64, 9.66, 9.68, 9.7,  9.8],\n",
        "               'random_state':[seed]}\n",
        "\n",
        "grid_search_cv(ridge, ridge_params)\n",
        "ridge_best_params, ridge_best_score = best_params, best_score\n",
        "print('Ridge best params:{} & best_score:{:0.5f}' .format(ridge_best_params, ridge_best_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrJig9H4CDV1"
      },
      "outputs": [],
      "source": [
        "'''Define hyperparameters of Elastic net.'''\n",
        "elastic_params = {'alpha': [ 0.0003, 0.00035, 0.00045, 0.0005], \n",
        "                 'l1_ratio': [0.80, 0.85, 0.9, 0.95],\n",
        "                 'random_state':[seed]}\n",
        "grid_search_cv(elnt, elastic_params)\n",
        "elastic_best_params, elastic_best_score = best_params, best_score\n",
        "print('Elastic Net best params:{} & best_score:{:0.5f}' .format(elastic_best_params, elastic_best_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCw0YTIOCGDz"
      },
      "outputs": [],
      "source": [
        "# '''Define hyperparameters of support vector machine'''\n",
        "# svm_params = {\n",
        "#     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], # precomputed is omitted from kernel to avoid error.\n",
        "#     'C': [4, 5], \n",
        "#     'gamma':[0.0001, 0.001]}\n",
        "\n",
        "# grid_search_cv(svm, svm_params)\n",
        "# svm_best_params, svm_best_score = best_params, best_score\n",
        "# print('SVM best params:{} & best_score:{:0.5f}' .format(svm_best_params, svm_best_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHYYBJ5zCJwR"
      },
      "outputs": [],
      "source": [
        "'''Hyperparameters of xgb'''\n",
        "xgb_opt = XGBRegressor(colsample_bytree = 0.4603, gamma = 0.0468, \n",
        "                             learning_rate = 0.04, max_depth = 3, \n",
        "                             min_child_weight = 1.7817, n_estimators = 2500,\n",
        "                             reg_alpha = 0.4640, reg_lambda = 0.8571,\n",
        "                             subsample = 0.5213, silent = 1,\n",
        "                             nthread = -1, random_state = 7)\n",
        "\n",
        "'''Hyperparameters of gb'''\n",
        "gb_opt = GradientBoostingRegressor(n_estimators = 3000, learning_rate = 0.05,\n",
        "                                   max_depth = 4, max_features = 'sqrt',\n",
        "                                   min_samples_leaf = 15, min_samples_split = 10, \n",
        "                                   loss = 'huber', random_state = seed)\n",
        "\n",
        "# '''Hyperparameters of lgb'''\n",
        "# lgb_opt = LGBMRegressor(objective = 'regression', num_leaves = 5,\n",
        "#                               learning_rate=0.05, n_estimators = 660,\n",
        "#                               max_bin = 55, bagging_fraction = 0.8,\n",
        "#                               bagging_freq = 5, feature_fraction = 0.2319,\n",
        "#                               feature_fraction_seed = 9, bagging_seed = 9,\n",
        "#                               min_data_in_leaf = 6, min_sum_hessian_in_leaf = 11)\n",
        "\n",
        "xgb_best_score = cross_validate(xgb_opt)\n",
        "gb_best_score = cross_validate(gb_opt)\n",
        "# lgb_best_score = cross_validate(lgb_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFz5KRmzCMb2"
      },
      "outputs": [],
      "source": [
        "\"\"\"Let's plot the models' rmse after optimization.\"\"\"\n",
        "optimized_scores = pd.DataFrame({'Optimized Scores':np.round([lasso_best_score, ridge_best_score, \n",
        "                  elastic_best_score, xgb_best_score, gb_best_score], 5)})\n",
        "optimized_scores.index = ['Lasso', 'Ridge', 'E_net', 'XGB', 'GB']\n",
        "optimized_scores.sort_values(by = 'Optimized Scores')\n",
        "optimized_scores\n",
        "# sns.scatter_plot(optimized_scores.index, optimized_scores['Optimized Scores'], \"Models' Scores after Optimization\", 'Models','Optimized Scores', 40, 'Rainbow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brxXSJ4NCUax"
      },
      "outputs": [],
      "source": [
        "lasso_opt = Lasso(**lasso_best_params)\n",
        "ridge_opt = Ridge(**ridge_best_params)\n",
        "# kernel_ridge_opt = KernelRidge(**kernel_best_params)\n",
        "elastic_net_opt = ElasticNet(**elastic_best_params)\n",
        "# svm_opt = SVR(**svm_best_params)\n",
        "xgb_opt = xgb_opt\n",
        "gb_opt = gb_opt\n",
        "# lgb_opt = lgb_opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XCkEudgCXSW"
      },
      "outputs": [],
      "source": [
        "'''Now train and predict with optimized models'''\n",
        "def predict_with_optimized_models(model):\n",
        "    model.fit(df_train_final, y_train)\n",
        "    y_pred = model.predict(sample)\n",
        "    submission = pd.DataFrame()\n",
        "    submission['Id']= sample.index\n",
        "    submission['SalePrice'] = y_pred\n",
        "    return submission\n",
        "path =\"./submission/0701\"\n",
        "!mkdir -p \"./submission/0701\"\n",
        "'''Make submission with optimized lasso, ridge, kernel_ridge, elastic_net and svm, xgb, gb, and lgb.'''\n",
        "predict_with_optimized_models(lasso_opt).to_csv(path+'/submission/0701/lasso_optimized.csv', index = False)\n",
        "predict_with_optimized_models(ridge_opt).to_csv(path+'/submission/0701/ridge_optimized.csv', index = False)\n",
        "# predict_with_optimized_models(kernel_ridge_opt).to_csv('/content/gdrive/MyDrive/Defi/kernel_ridge_optimized.csv', index = False)\n",
        "predict_with_optimized_models(elastic_net_opt).to_csv(path+'/submission/0701/elastic_net_optimized.csv', index = False)\n",
        "# predict_with_optimized_models(svm_opt).to_csv('./submission/0701/svm_opt_optimized.csv', index = False)\n",
        "predict_with_optimized_models(xgb_opt).to_csv(path+'/submission/0701/xgb_optimized.csv', index = False)\n",
        "predict_with_optimized_models(gb_opt).to_csv(path+'/submission/0701/gb_optimized.csv', index = False)\n",
        "# predict_with_optimized_models(lgb_opt).to_csv('/content/gdrive/MyDrive/Defi/lgb_optimized.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
